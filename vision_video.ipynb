{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7410ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import time # Para medir el tiempo de procesamiento\n",
    "\n",
    "# Nota: glob y matplotlib ya no son necesarios para la l√≥gica principal del video.\n",
    "\n",
    "def dibujar_resultados_y_verificar(frame, resultados, modelo, color=(255, 0, 255)):\n",
    "    \"\"\"\n",
    "    Dibuja las cajas de detecci√≥n en un frame y devuelve los nombres de las clases detectadas.\n",
    "    \"\"\"\n",
    "    clases_detectadas = set() # Usamos un set para evitar duplicados\n",
    "\n",
    "    for r in resultados:\n",
    "        for box in r.boxes:\n",
    "            # Extraer informaci√≥n de la caja\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls_id = int(box.cls[0])\n",
    "            nombre_clase = modelo.names[cls_id]\n",
    "\n",
    "            # A√±adir la clase al set\n",
    "            clases_detectadas.add(nombre_clase)\n",
    "\n",
    "            # Dibujar el rect√°ngulo\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Preparar y dibujar la etiqueta\n",
    "            etiqueta = f\"{nombre_clase} {conf:.2f}\"\n",
    "            cv2.putText(frame, etiqueta, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    return frame, clases_detectadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64667f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modelo de ACCIDENTES cargado exitosamente.\n",
      "   Clases: {0: 'accident', 1: 'moderate', 2: 'severe'}\n",
      "‚úÖ Modelo de FUEGO/HUMO cargado exitosamente.\n",
      "   Clases: {0: 'Fire', 1: 'Smoke'}\n",
      "‚úÖ Modelo de personas cargado exitosamente.\n",
      "   Clases: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'bus', 5: 'train', 6: 'truck', 7: 'cat', 8: 'dog', 9: 'backpack', 10: 'handbag', 11: 'suitcase', 12: 'sports ball', 13: 'baseball bat', 14: 'skateboard', 15: 'tennis racket', 16: 'bottle', 17: 'fork', 18: 'knife', 19: 'spoon', 20: 'scissors', 21: 'handgun', 22: 'Fire'}\n"
     ]
    }
   ],
   "source": [
    "# --- RUTAS ---\n",
    "# Rutas a tus modelos .pt\n",
    "ruta_modelo_accidentes = 'best_accident.pt'\n",
    "ruta_modelo_fuego = 'best_fire.pt'\n",
    "ruta_modelo_personas = 'best_general.pt'\n",
    "\n",
    "# Ruta del video que quieres analizar\n",
    "ruta_video_entrada = 'videos/video8.mp4' # <-- CAMBIA ESTO por la ruta de tu video\n",
    "\n",
    "# Ruta donde se guardar√° el video con las detecciones\n",
    "ruta_video_salida = 'videos/salida/video_salida8.mp4'\n",
    "\n",
    "# --- PAR√ÅMETROS DE DETECCI√ìN ---\n",
    "# Umbrales de confianza para cada modelo\n",
    "confianza_accidentes = 0.85\n",
    "confianza_fuego = 0.4\n",
    "confianza_personas = 0.5\n",
    "\n",
    "# --- PAR√ÅMETRO DE RENDIMIENTO ---\n",
    "# Analizar un fotograma cada 'x' fotogramas.\n",
    "# 1 = analizar todos. 5 = analizar 1 de cada 5. Mayor n√∫mero = m√°s r√°pido.\n",
    "procesar_cada_x_frames = 30\n",
    "\n",
    "# Cargar modelo de accidentes\n",
    "try:\n",
    "    modelo_accidentes = YOLO(ruta_modelo_accidentes)\n",
    "    print(\"‚úÖ Modelo de ACCIDENTES cargado exitosamente.\")\n",
    "    print(\"   Clases:\", modelo_accidentes.names)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar el modelo de accidentes '{ruta_modelo_accidentes}': {e}\")\n",
    "    modelo_accidentes = None\n",
    "\n",
    "# Cargar modelo de fuego y humo\n",
    "try:\n",
    "    modelo_fuego = YOLO(ruta_modelo_fuego)\n",
    "    print(\"‚úÖ Modelo de FUEGO/HUMO cargado exitosamente.\")\n",
    "    print(\"   Clases:\", modelo_fuego.names)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar el modelo de fuego '{ruta_modelo_fuego}': {e}\")\n",
    "    modelo_fuego = None\n",
    "\n",
    "\n",
    "\n",
    "# Cargar modelo de personas\n",
    "try:\n",
    "    modelo_personas = YOLO(ruta_modelo_personas)\n",
    "    print(\"‚úÖ Modelo de personas cargado exitosamente.\")\n",
    "    print(\"   Clases:\", modelo_personas.names)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al cargar el modelo de personas: {e}\")\n",
    "    modelo_personas = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855849d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892232dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Iniciando procesamiento del video: videos/video8.mp4\n",
      "   - Analizando 1 de cada 30 fotogramas.\n",
      "   - El video de salida se guardar√° en: videos/salida/video_salida8.mp4\n",
      "   Analizando fotograma #30...\n",
      "   Analizando fotograma #60...\n",
      "   Analizando fotograma #90...\n",
      "   Analizando fotograma #120...\n",
      "   Analizando fotograma #150...\n",
      "   Analizando fotograma #180...\n",
      "   Analizando fotograma #210...\n",
      "   Analizando fotograma #240...\n",
      "   Analizando fotograma #270...\n",
      "   Analizando fotograma #300...\n",
      "   Analizando fotograma #330...\n",
      "   Analizando fotograma #360...\n",
      "   Analizando fotograma #390...\n",
      "   Analizando fotograma #420...\n",
      "   Analizando fotograma #450...\n",
      "   Analizando fotograma #480...\n",
      "   Analizando fotograma #510...\n",
      "   Analizando fotograma #540...\n",
      "   Analizando fotograma #570...\n",
      "   Analizando fotograma #600...\n",
      "   Analizando fotograma #630...\n",
      "   Analizando fotograma #660...\n",
      "   Analizando fotograma #690...\n",
      "   Analizando fotograma #720...\n",
      "   Analizando fotograma #750...\n",
      "   Analizando fotograma #780...\n",
      "   Analizando fotograma #810...\n",
      "   Analizando fotograma #840...\n",
      "   Analizando fotograma #870...\n",
      "   Analizando fotograma #900...\n",
      "   Analizando fotograma #930...\n",
      "   Analizando fotograma #960...\n",
      "   Analizando fotograma #990...\n",
      "   Analizando fotograma #1020...\n",
      "   Analizando fotograma #1050...\n",
      "   Analizando fotograma #1080...\n",
      "   Analizando fotograma #1110...\n",
      "   Analizando fotograma #1140...\n",
      "   Analizando fotograma #1170...\n",
      "   Analizando fotograma #1200...\n",
      "   Analizando fotograma #1230...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 101\u001b[0m\n\u001b[0;32m     99\u001b[0m cap\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    100\u001b[0m out\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m--> 101\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ ¬°Proceso de video completado!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   - Tiempo total de procesamiento: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m segundos.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1295: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvDestroyAllWindows'\n"
     ]
    }
   ],
   "source": [
    "# <-- MODIFICADO: Verificar que los TRES modelos y el video de entrada existan -->\n",
    "if modelo_accidentes is None or modelo_fuego is None or modelo_personas is None:\n",
    "    print(\"‚ö†Ô∏è No se puede continuar porque uno o m√°s modelos no se cargaron correctamente.\")\n",
    "elif not os.path.exists(ruta_video_entrada):\n",
    "    print(f\"‚ùå Error: El video de entrada no se encontr√≥ en '{ruta_video_entrada}'\")\n",
    "else:\n",
    "    # --- INICIALIZACI√ìN DEL VIDEO ---\n",
    "    cap = cv2.VideoCapture(ruta_video_entrada)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"‚ùå Error al abrir el archivo de video: {ruta_video_entrada}\")\n",
    "    else:\n",
    "        # Obtener propiedades del video para el archivo de salida\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        # Definir el codec y crear el objeto VideoWriter\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Codec para .mp4\n",
    "        out = cv2.VideoWriter(ruta_video_salida, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        print(f\"\\nüöÄ Iniciando procesamiento del video: {ruta_video_entrada}\")\n",
    "        print(f\"   - Analizando 1 de cada {procesar_cada_x_frames} fotogramas.\")\n",
    "        print(f\"   - El video de salida se guardar√° en: {ruta_video_salida}\")\n",
    "\n",
    "        # --- VARIABLES PARA EL BUCLE ---\n",
    "        frame_count = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # <-- MODIFICADO: Banderas de alerta para el resumen final -->\n",
    "        alerta_fuego_activada = False\n",
    "        alerta_accidente_activada = False\n",
    "        alerta_personas_activada = False # <-- NUEVO\n",
    "\n",
    "        # <-- MODIFICADO: Almacenar los √∫ltimos resultados para dibujarlos en frames intermedios -->\n",
    "        ultimos_resultados_accidentes = []\n",
    "        ultimos_resultados_fuego = []\n",
    "        ultimos_resultados_personas = [] # <-- NUEVO\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break # Fin del video\n",
    "\n",
    "            frame_count += 1\n",
    "            \n",
    "            # --- L√ìGICA DE PROCESAMIENTO CADA X FRAMES ---\n",
    "            if frame_count % procesar_cada_x_frames == 0:\n",
    "                # Solo en estos fotogramas ejecutamos los modelos\n",
    "                print(f\"   Analizando fotograma #{frame_count}...\")\n",
    "                \n",
    "                # Ejecutar modelo de ACCIDENTES\n",
    "                ultimos_resultados_accidentes = modelo_accidentes.predict(source=frame, conf=confianza_accidentes, verbose=False)\n",
    "                \n",
    "                # Ejecutar modelo de FUEGO/HUMO\n",
    "                ultimos_resultados_fuego = modelo_fuego.predict(source=frame, conf=confianza_fuego, verbose=False)\n",
    "\n",
    "                # <-- NUEVO: Ejecutar modelo de personas -->\n",
    "                ultimos_resultados_personas = modelo_personas.predict(source=frame, conf=confianza_personas, verbose=False)\n",
    "\n",
    "            # --- DIBUJAR Y VERIFICAR ALERTAS (en todos los frames) ---\n",
    "            # Usamos los √∫ltimos resultados guardados para que el video sea fluido\n",
    "            clases_detectadas_total = set()\n",
    "            \n",
    "            if ultimos_resultados_accidentes:\n",
    "                frame, clases_acc = dibujar_resultados_y_verificar(frame, ultimos_resultados_accidentes, modelo_accidentes, color=(0, 255, 255)) # Cyan\n",
    "                clases_detectadas_total.update(clases_acc)\n",
    "            \n",
    "            if ultimos_resultados_fuego:\n",
    "                frame, clases_fue = dibujar_resultados_y_verificar(frame, ultimos_resultados_fuego, modelo_fuego, color=(0, 0, 255)) # Rojo\n",
    "                clases_detectadas_total.update(clases_fue)\n",
    "            \n",
    "            # <-- NUEVO: Dibujar resultados del modelo de personas -->\n",
    "            if ultimos_resultados_personas:\n",
    "                # Usamos un color diferente, por ejemplo, magenta\n",
    "                frame, clases_arm = dibujar_resultados_y_verificar(frame, ultimos_resultados_personas, modelo_personas, color=(255, 0, 255)) # Magenta\n",
    "                clases_detectadas_total.update(clases_arm)\n",
    "\n",
    "\n",
    "            # <-- MODIFICADO: Comprobar si se debe activar alguna alerta global -->\n",
    "            # (Asume nombres de clases. ¬°Aj√∫stalos si tus modelos usan otros nombres!)\n",
    "            if any(cls in ['Fire', 'Smoke'] for cls in clases_detectadas_total):\n",
    "                alerta_fuego_activada = True\n",
    "            \n",
    "            if any(cls in ['Accident', 'accident', 'accidente'] for cls in clases_detectadas_total):\n",
    "                alerta_accidente_activada = True\n",
    "\n",
    "            # <-- NUEVO: Comprobar alerta de personas -->\n",
    "            if any(cls in ['Weapon', 'weapon', 'gun', 'pistol', 'rifle', 'arma', 'pistola'] for cls in clases_detectadas_total):\n",
    "                alerta_personas_activada = True\n",
    "\n",
    "            # Escribir el frame procesado en el video de salida\n",
    "            out.write(frame)\n",
    "\n",
    "        # --- FINALIZACI√ìN ---\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        \n",
    "        # Liberar recursos\n",
    "        cap.release()\n",
    "        out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        print(\"\\n‚úÖ ¬°Proceso de video completado!\")\n",
    "        print(f\"   - Tiempo total de procesamiento: {total_time:.2f} segundos.\")\n",
    "        print(f\"   - Total de fotogramas procesados: {frame_count}\")\n",
    "\n",
    "        # <-- MODIFICADO: INFORME FINAL DE ALERTAS ---\n",
    "        print(\"\\n--- üö® INFORME DE ALERTAS DEL VIDEO üö® ---\")\n",
    "        if not alerta_fuego_activada and not alerta_accidente_activada and not alerta_personas_activada:\n",
    "            print(\"üü¢ No se detectaron riesgos de incendio, accidentes o personas en el video.\")\n",
    "        else:\n",
    "            if alerta_fuego_activada:\n",
    "                print(\"üî• ALERTA: Se ha detectado RIESGO DE INCENDIO/HUMO en el video.\")\n",
    "            if alerta_accidente_activada:\n",
    "                print(\"üöó ALERTA: Se ha detectado un posible ACCIDENTE AUTOMOVIL√çSTICO en el video.\")\n",
    "            if alerta_personas_activada:\n",
    "                print(\"üî´ ALERTA: Se ha detectado la presencia de personas en el video.\") # <-- NUEVO\n",
    "        print(\"------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
