# app.py (Versi√≥n 5.0 - Doble Pipeline: Monitoreo y B√∫squeda)
import streamlit as st
import os
import tempfile
from ultralytics import YOLO
from dotenv import load_dotenv
import google.generativeai as genai

from src.agents.interpreted import interpret_and_dispatch
from src.pipelines import (
    run_monitor_pipeline,
    run_search_pipeline
)


# --- CONFIGURACI√ìN DE LA P√ÅGINA ---
st.set_page_config(page_title="Sistema de Vigilancia IA", layout="wide")

# --- 1. CONFIGURACI√ìN INICIAL Y CARGA DE MODELOS ---
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("No se encontr√≥ la clave GEMINI_API_KEY. Aseg√∫rate de crear un archivo .env.")
    st.stop()
genai.configure(api_key=GEMINI_API_KEY)
TEXT_MODEL = os.getenv("TEXT_MODEL", "gemini-2.0-flash")
VIDEO_MODEL = os.getenv("VIDEO_MODEL", "gemini-2.0-flash")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
OUTPUT_DIR = os.path.join(BASE_DIR, "data/output_captures")
os.makedirs(OUTPUT_DIR, exist_ok=True)

@st.cache_resource
def load_models():
    """Carga los modelos de IA una sola vez."""
    with st.spinner("Cargando modelos de IA (esto solo sucede la primera vez)..."):
        intention_to_model_path = {
            "accidente": os.path.join(BASE_DIR, "weights", "best_accident.pt"),
            "fuego": os.path.join(BASE_DIR, "weights", "best_fire.pt"),
            "general": os.path.join(BASE_DIR, "weights", "best_general.pt")
        }
        models = {name: YOLO(path) for name, path in intention_to_model_path.items()}
        vision_model = genai.GenerativeModel(VIDEO_MODEL)
        text_model = genai.GenerativeModel(TEXT_MODEL)

        agents = {
            "vision_model": vision_model,
            "text_model": text_model
        }
        return models, agents

detection_models, agents = load_models()

# --- L√ìGICA PRINCIPAL DE LA APP ---
st.title("üëÅÔ∏è Sistema de Vigilancia con Agentes de IA v5.1")
st.markdown("**Modos duales:** Monitorea eventos o busca objetos con caracter√≠sticas espec√≠ficas.")

col1, col2 = st.columns([2, 3])
with col1:
    st.header("1. Carga tu Video")
    uploaded_file = st.file_uploader("Selecciona un archivo", type=["mp4", "mov", "avi"])
with col2:
    st.header("2. Define la Tarea y Configuraci√≥n")
    user_intention = st.text_area("Describe la intenci√≥n:", "Encuentra todos los coches de color rojo.", height=100)

    sub_col1, sub_col2, sub_col3 = st.columns(3)
    with sub_col1:
        confidence = st.slider("Confianza Detecci√≥n", 0.1, 1.0, 0.4, 0.05)
    with sub_col2:
        # Modifiqu√© el help text para que sea m√°s claro
        frame_skip = st.slider("Analizar 1/N frames", 1, 30, 5, help="Afecta a ambos modos: Monitoreo y B√∫squeda")
    with sub_col3:
        capture_duration_option = st.selectbox("Duraci√≥n Captura", ["5 segundos", "10 segundos"], help="Solo para modo Monitoreo")
        capture_duration = int(capture_duration_option.split(" ")[0])

if st.button("üöÄ Procesar Video", use_container_width=True):
    # --- PASO 1: Validaci√≥n de entradas del usuario ---
    if not uploaded_file:
        st.warning("Por favor, sube un archivo de video.")
    elif not user_intention or not user_intention.strip():
        st.warning("Por favor, describe una intenci√≥n de vigilancia.")
    else:
        # Si las validaciones son correctas, se ejecuta el resto.

        # --- PASO 2: Guardar el video y preparar la UI ---
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile:
            tfile.write(uploaded_file.read())
            video_path = tfile.name

        st.header("üìä Resultados del An√°lisis")
        progress_bar = st.progress(0, text="Iniciando...")
        status_text = st.empty()

        # --- PASO 3: Llamar al Agente 1 (Despachador) ---
        # Esta llamada se hace UNA SOLA VEZ, al principio.
        dispatch_result, error, raw_response = interpret_and_dispatch(agents["text_model"], user_intention)
        if error:
            st.error(f"Error del Agente Despachador: {error}")
            st.text_area(raw_response, height=150)
            status_text.text("Error.")
            progress_bar.empty()
        

        # --- PASO 4: Ejecutar el pipeline correspondiente ---
        if not dispatch_result or "workflow" not in dispatch_result:
            st.error("El Agente Despachador no pudo determinar un flujo de trabajo. Intenta reformular tu solicitud.")
            status_text.text("Error.")
            progress_bar.empty()

        elif dispatch_result["workflow"] == "monitor":
            run_monitor_pipeline(
                st=st,
                agents=agents,
                detection_models=detection_models,
                video_path=video_path,
                user_intention=user_intention,
                surveillance_config=dispatch_result["config"],
                confidence_threshold=confidence,
                frame_processing_rate=frame_skip,
                capture_duration=capture_duration,
                progress_bar=progress_bar,
                status_text=status_text
            )

        elif dispatch_result["workflow"] == "search":
            config = dispatch_result["config"]
            run_search_pipeline(
                st=st,
                agents=agents,
                detection_models=detection_models,
                video_path=video_path,
                base_class=config.get("base_class", ""),
                specific_property=config.get("specific_property", ""),
                confidence_threshold=confidence,
                frame_processing_rate=frame_skip, # Pasamos el par√°metro
                progress_bar=progress_bar,
                status_text=status_text
            )

        # --- PASO 5: Limpiar el archivo de video temporal ---
        os.remove(video_path)


# --- INSTRUCCIONES PARA EL USUARIO ---
st.markdown("---")
st.subheader("Instrucciones:")
st.markdown("""
1.  **Configura tu clave API de Gemini:** Crea un archivo `.env` en la ra√≠z de tu proyecto con el contenido `GEMINI_API_KEY='tu_clave_api_aqui'`.
2.  **Carga tu Video:** Sube un archivo de video (MP4, MOV, AVI).
3.  **Define la Tarea:** En el √°rea de texto, describe claramente lo que el sistema debe vigilar (ej. "identificar **accidente** de transito", "detectar **fuego**", "buscar **persona** sospechosa").
    * **¬°Importante!** Intenta usar palabras clave que coincidan con tus modelos YOLO si tienes modelos espec√≠ficos.
4.  **Ajusta "Confianza Detecci√≥n (YOLO)":** Umbral de confianza para las detecciones de YOLO. Un valor m√°s alto significa menos falsos positivos.
5.  **Ajusta "Analizar 1/N frames":** Controla la frecuencia del an√°lisis de **YOLO**.
6.  **Ajusta "Duraci√≥n de Captura Temporal":** Define cu√°nto tiempo (antes y despu√©s) se analizar√° el video alrededor de una posible detecci√≥n.
7.  **Procesar:** Haz clic en "üöÄ Procesar Video y Analizar Eventos".
    * El **Agente 1** interpretar√° tu intenci√≥n.
    * **YOLO** analizar√° el video fotograma a fotograma. Se intentar√° usar un modelo YOLO espec√≠fico si tu intenci√≥n lo sugiere (ej. "accidente" -> `best_accident.pt`). Si no hay uno espec√≠fico, usar√° el modelo `general`.
    * **Solo si YOLO detecta algo relevante** (coincidencia con palabras clave), el fotograma se pasar√° al **Agente 2**.
    * Si el **Agente 2** clasifica una posible emergencia, el **Agente 3** realizar√° un an√°lisis temporal para confirmarla o refutarla.
""")
st.warning("El an√°lisis de video con modelos de IA es intensivo. Usa videos cortos para pruebas. Un mayor n√∫mero de frames (menor `Analizar 1/N`) y una mayor `Duraci√≥n de Captura Temporal` aumentar√°n el costo y el tiempo de procesamiento.")
